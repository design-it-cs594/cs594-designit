{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import scipy.io as sio\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from model import DeepLabResNetModel\n",
    "\n",
    "\n",
    "def load(saver, sess, ckpt_path):\n",
    "    saver.restore(sess, ckpt_path)\n",
    "    print(\"Restored model parameters from {}\".format(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful load img: input/paper2.jpg\n"
     ]
    }
   ],
   "source": [
    "IMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n",
    "\n",
    "img_path = \"input/paper2.jpg\"\n",
    "filename = img_path.split('/')[-1]\n",
    "file_type = filename.split('.')[-1]\n",
    "restore_from = \"restore_weights\"\n",
    "\n",
    "# testing if image file exists\n",
    "if os.path.isfile(img_path):\n",
    "    print('successful load img: {0}'.format(img_path))\n",
    "else:\n",
    "    print('not found file: {0}'.format(img_path))\n",
    "    sys.exit(0)\n",
    "\n",
    "# Prepare image.\n",
    "if file_type.lower() == 'png':\n",
    "    img = tf.image.decode_png(tf.read_file(img_path), channels=3)\n",
    "elif file_type.lower() == 'jpg':\n",
    "    img = tf.image.decode_jpeg(tf.read_file(img_path), channels=3)\n",
    "else:\n",
    "    print('cannot process {0} file.'.format(file_type))\n",
    "\n",
    "# Convert RGB to BGR.\n",
    "img_r, img_g, img_b = tf.split(axis=2, num_or_size_splits=3, value=img)\n",
    "img = tf.cast(tf.concat(axis=2, values=[img_b, img_g, img_r]), dtype=tf.float32)\n",
    "# Extract mean.\n",
    "img -= IMG_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:180: calling expand_dims (from tensorflow.python.ops.array_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-b0a8e7d2f071>:12: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from restore_weights\\model.ckpt-100000\n",
      "Restored model parameters from restore_weights\\model.ckpt-100000\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 27\n",
    "\n",
    "# Create network.\n",
    "net = DeepLabResNetModel({'data': tf.expand_dims(img, dim=0)}, is_training=False, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Which variables to load.\n",
    "restore_var = tf.global_variables()\n",
    "\n",
    "# Predictions.\n",
    "raw_output = net.layers['fc_out']\n",
    "raw_output_up = tf.image.resize_bilinear(raw_output, tf.shape(img)[0:2,])\n",
    "raw_output_up = tf.argmax(raw_output_up, dimension=3)\n",
    "pred = tf.expand_dims(raw_output_up, dim=3)\n",
    "\n",
    "# Set up TF session and initialize variables.\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "# Load weights.\n",
    "ckpt = tf.train.get_checkpoint_state(restore_from)\n",
    "\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    loader = tf.train.Saver(var_list=restore_var)\n",
    "    load_step = int(os.path.basename(ckpt.model_checkpoint_path).split('-')[1])\n",
    "    load(loader, sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print('No checkpoint file found.')\n",
    "    load_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference.\n",
    "preds = sess.run(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "\n",
    "classification_inputs = tf.saved_model.utils.build_tensor_info(pred)\n",
    "classification_output_classes = tf.saved_model.utils.build_tensor_info(pred)\n",
    "\n",
    "classification_signature = ( tf.saved_model.signature_def_utils.build_signature_def (\n",
    "    inputs  = { tf.saved_model.signature_constants.CLASSIFY_INPUTS         : classification_inputs },\n",
    "    outputs = { tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES : classification_output_classes },\n",
    "    method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME ) )\n",
    "\n",
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder( \"message-classification-model-dir2\" )\n",
    "builder.add_meta_graph_and_variables(\n",
    "      sess, [ tf.saved_model.tag_constants.SERVING ],\n",
    "      signature_def_map={ \"classify_message\" : classification_signature, },\n",
    "      main_op=tf.tables_initializer() )\n",
    "builder.save()\n",
    "\n",
    "!tar -zcvf message-classification-model.tar.gz -C message-classification-model-dir2 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Watson Machine Learning client instance\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "wml_credentials = {\n",
    "    \"apikey\"    : \"Add here\",\n",
    "    \"instance_id\" : \"Add here,\n",
    "    \"url\"    : \"Add here\"\n",
    "}\n",
    "client = WatsonMachineLearningAPIClient( wml_credentials )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting model ready for deployment\n",
    "\n",
    "metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"TensorFlow model\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_NAME: \"tensorflow\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"1.14\"\n",
    "}\n",
    "model_details_targz = client.repository.store_model( model=\"message-classification-model.tar.gz\", meta_props=metadata )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the stored model as an online web service deployment\n",
    "\n",
    "model_id_dir = model_details_targz[\"metadata\"][\"guid\"]\n",
    "deployment_details_dir = client.deployments.create( artifact_uid=model_id_dir, name=\"TensorFlow deployment\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
